{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033eb8f7",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "This notebook will:\n",
    "1) Load `data/x_train.pkl` and `data/x_test.pkl`\n",
    "2) Train a tiny VAE-style seq2seq model on 60â†’10 windows from `x_train`\n",
    "3) During training, run on-train validation:\n",
    "   - Official metrics: MSE, MAE, IC, IR, SharpeRatio, MDD, VaR, ES\n",
    "   - Cross-sectional trading snapshots: CSM and LOTQ\n",
    "4) Run inference on `x_test` and save a PICKLE submission at `sample_submission/submission.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e7e5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53a7239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths (adjust if your layout differs)\n",
    "ROOT = Path.cwd().parent if (Path.cwd().name == 'src') else Path.cwd()\n",
    "DATA = ROOT / \"data\"\n",
    "SRC  = ROOT / \"src\"\n",
    "SUBM = ROOT / \"sample_submission\"\n",
    "\n",
    "# Ensure src is importable\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Create sample_submission dir if missing\n",
    "SUBM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0683b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_info.json loaded. Keys: ['freq', 'features', 'input_len', 'horizon_len', 'test_windowing', 'shuffle_seed', 'dtypes', 'outputs', 'sha256']\n",
      "{\n",
      "  \"features\": [\n",
      "    \"close\",\n",
      "    \"volume\"\n",
      "  ],\n",
      "  \"input_len\": 60,\n",
      "  \"horizon_len\": 10,\n",
      "  \"outputs\": {\n",
      "    \"x_train\": {\n",
      "      \"columns\": [\n",
      "        \"series_id\",\n",
      "        \"time_step\",\n",
      "        \"close\",\n",
      "        \"volume\"\n",
      "      ]\n",
      "    },\n",
      "    \"x_test\": {\n",
      "      \"columns\": [\n",
      "        \"window_id\",\n",
      "        \"time_step\",\n",
      "        \"close\",\n",
      "        \"volume\"\n",
      "      ]\n",
      "    },\n",
      "    \"y_test\": {\n",
      "      \"columns\": [\n",
      "        \"window_id\",\n",
      "        \"time_step\",\n",
      "        \"close\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "x_train shape: (18331224, 4) | columns: ['series_id', 'time_step', 'close', 'volume']\n",
      "x_test  shape: (3000000, 4) | columns: ['window_id', 'time_step', 'close', 'volume']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>171985.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>85451.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13647</td>\n",
       "      <td>121151.898438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  time_step    close         volume\n",
       "0          0          0  0.13700  171985.703125\n",
       "1          0          1  0.13656   85451.398438\n",
       "2          0          2  0.13647  121151.898438"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>24976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>2299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_id  time_step   close   volume\n",
       "0          1          0  0.1126  24976.0\n",
       "1          1          1  0.1126      0.0\n",
       "2          1          2  0.1125   2299.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset files\n",
    "info_path = DATA / \"dataset_info.json\"\n",
    "if info_path.exists():\n",
    "    info = json.loads(info_path.read_text(encoding=\"utf-8\"))\n",
    "    print(\"dataset_info.json loaded. Keys:\", list(info.keys()))\n",
    "    print(json.dumps({k: info[k] for k in ['features','input_len','horizon_len','outputs']}, indent=2))\n",
    "else:\n",
    "    print(\"dataset_info.json not found at\", info_path)\n",
    "\n",
    "# Peek x_train / x_test\n",
    "x_train_path = DATA / \"x_train.pkl\"\n",
    "x_test_path  = DATA / \"x_test.pkl\"\n",
    "\n",
    "x_train = pd.read_pickle(x_train_path)\n",
    "x_test  = pd.read_pickle(x_test_path)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"| columns:\", x_train.columns.tolist())\n",
    "print(\"x_test  shape:\", x_test.shape,  \"| columns:\", x_test.columns.tolist())\n",
    "\n",
    "display(x_train.head(3))\n",
    "display(x_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be805975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, (50000, 60, 2), (50000, 10))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the sampler logic from src/dataset.py to slice windows\n",
    "from dataset import TrainWindowSampler\n",
    "\n",
    "class WindowsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrap TrainWindowSampler into a PyTorch Dataset.\n",
    "    Returns:\n",
    "      X: (60, 2) float32 -> [close, volume]\n",
    "      y: (10,)  float32 -> future close\n",
    "    \"\"\"\n",
    "    def __init__(self, x_train_path: str, rolling: bool = True, step_size: int = 1, max_samples: int = None):\n",
    "        self.sampler = TrainWindowSampler(\n",
    "            x_train_path=x_train_path,\n",
    "            window=70,\n",
    "            input_len=60,\n",
    "            horizon_len=10,\n",
    "            rolling=rolling,\n",
    "            step_size=step_size,\n",
    "            seed=SEED,\n",
    "        )\n",
    "        # Materialize (optionally capped) for stable batching\n",
    "        xs, ys = [], []\n",
    "        for i, (X, y) in enumerate(self.sampler.iter_windows()):\n",
    "            xs.append(X.astype(np.float32))\n",
    "            ys.append(y.astype(np.float32))\n",
    "            if max_samples is not None and (i + 1) >= max_samples:\n",
    "                break\n",
    "        self.X = np.stack(xs, axis=0) if xs else np.zeros((0,60,2), dtype=np.float32)\n",
    "        self.y = np.stack(ys, axis=0) if ys else np.zeros((0,10), dtype=np.float32)\n",
    "\n",
    "    def __len__(self):  return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return torch.from_numpy(self.X[i]), torch.from_numpy(self.y[i])\n",
    "\n",
    "# For a quick demo, cap samples. Increase for better quality.\n",
    "MAX_SAMPLES = 50_000  # set to None to use all windows\n",
    "train_ds = WindowsDataset(str(x_train_path), rolling=True, step_size=1, max_samples=MAX_SAMPLES)\n",
    "len(train_ds), train_ds.X.shape, train_ds.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37af254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2048, 60, 2), (2048, 10), (2048,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a tiny validation set from x_train for on-train evaluation\n",
    "# We reuse TrainWindowSampler and materialize ~N windows into memory.\n",
    "\n",
    "def build_val_windows(x_train_path: str, max_val_windows: int = 2048):\n",
    "    sampler = TrainWindowSampler(\n",
    "        x_train_path=x_train_path,\n",
    "        window=70, input_len=60, horizon_len=10,\n",
    "        rolling=True, step_size=50, seed=2025  # sparser step for speed\n",
    "    )\n",
    "    Xs, Ys, base_closes = [], [], []\n",
    "    cnt = 0\n",
    "    for X, y in sampler.iter_windows():\n",
    "        Xs.append(X.astype(np.float32))\n",
    "        Ys.append(y.astype(np.float32))\n",
    "        base_closes.append(np.float32(X[-1, 0]))  # last input close -> base_close\n",
    "        cnt += 1\n",
    "        if cnt >= max_val_windows:\n",
    "            break\n",
    "    if not Xs:\n",
    "        raise ValueError(\"No validation windows produced.\")\n",
    "    X = np.stack(Xs, axis=0)           # (N,60,2)\n",
    "    Y = np.stack(Ys, axis=0)           # (N,10)\n",
    "    B = np.asarray(base_closes)        # (N,)\n",
    "    return X, Y, B\n",
    "\n",
    "X_val, Y_val, B_val = build_val_windows(str(x_train_path), max_val_windows=2048)\n",
    "X_val.shape, Y_val.shape, B_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8e305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159552a3449745c98ecfcc2e940c936d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.003801 recon=0.003673 kld=0.127999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c796016aca90480baf91bf98b529d545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.000267 recon=0.000202 kld=0.065022\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83d866137ba41e997a0f4f071726b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.000195 recon=0.000178 kld=0.016385\n",
      "Saved checkpoint to: c:\\Users\\xyy31\\Desktop\\ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit\\sample_submission\\tinytimevae_demo.pt\n"
     ]
    }
   ],
   "source": [
    "from baselines.vae_based import TinyTimeVAE, vae_loss\n",
    "\n",
    "# DataLoader\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 3           # increase for better quality\n",
    "LR = 1e-3\n",
    "BETA = 1e-3              # KL weight\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "# Model & optimizer\n",
    "model = TinyTimeVAE(input_dim=2, hidden=64, latent=16, input_len=60, horizon=10).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Train\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "    loss_avg, recon_avg, kld_avg, n_steps = 0.0, 0.0, 0.0, 0\n",
    "\n",
    "    for X, y in pbar:\n",
    "        X = X.to(torch.float32).to(DEVICE)     # (B,60,2)\n",
    "        y = y.to(torch.float32).to(DEVICE)     # (B,10)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        pred, mu, logvar = model(X)\n",
    "        loss, recon, kld = vae_loss(pred, y, mu, logvar, beta=BETA)\n",
    "        loss.backward()\n",
    "        if GRAD_CLIP is not None:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        n_steps += 1\n",
    "        loss_avg  += (loss.item() - loss_avg) / n_steps\n",
    "        recon_avg += (recon - recon_avg) / n_steps\n",
    "        kld_avg   += (kld   - kld_avg)   / n_steps\n",
    "        pbar.set_postfix(loss=f\"{loss_avg:.5f}\", recon=f\"{recon_avg:.5f}\", kld=f\"{kld_avg:.5f}\")\n",
    "\n",
    "    print(f\"[Epoch {epoch}] loss={loss_avg:.6f} recon={recon_avg:.6f} kld={kld_avg:.6f}\")\n",
    "\n",
    "# Optionally save a checkpoint\n",
    "CKPT = SUBM / \"tinytimevae_demo.pt\"\n",
    "torch.save(model.state_dict(), CKPT)\n",
    "print(\"Saved checkpoint to:\", CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606b9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a minibatch into y_true / y_pred / x_like frames compatible with metrics & trading\n",
    "\n",
    "def batch_to_eval_frames(pred: np.ndarray, y_true: np.ndarray, base_close: np.ndarray, start_id: int = 0):\n",
    "    \"\"\"\n",
    "    pred: (N,10) predicted close\n",
    "    y_true: (N,10) true close\n",
    "    base_close: (N,) last input close used as base\n",
    "    Returns:\n",
    "      y_true_df: ['window_id','time_step','close']\n",
    "      y_pred_df: ['window_id','time_step','pred_close']\n",
    "      x_like_df: ['window_id','time_step','close']  # only time_step=59 rows for base_close\n",
    "      y_true_with_base: ['window_id','time_step','close','base_close']  # for trading.py\n",
    "    \"\"\"\n",
    "    N, H = y_true.shape\n",
    "    wids = np.arange(start_id, start_id + N, dtype=np.int32)\n",
    "\n",
    "    rows_true, rows_pred, rows_xlike, rows_true_base = [], [], [], []\n",
    "    for i in range(N):\n",
    "        wid = int(wids[i])\n",
    "        rows_xlike.append({'window_id': wid, 'time_step': 59, 'close': float(base_close[i])})\n",
    "        for h in range(H):\n",
    "            rows_true.append({'window_id': wid, 'time_step': h, 'close': float(y_true[i, h])})\n",
    "            rows_pred.append({'window_id': wid, 'time_step': h, 'pred_close': float(pred[i, h])})\n",
    "            rows_true_base.append({\n",
    "                'window_id': wid, 'time_step': h,\n",
    "                'close': float(y_true[i, h]),\n",
    "                'base_close': float(base_close[i])\n",
    "            })\n",
    "    y_true_df = pd.DataFrame(rows_true)\n",
    "    y_pred_df = pd.DataFrame(rows_pred)\n",
    "    x_like_df = pd.DataFrame(rows_xlike)\n",
    "    y_true_with_base = pd.DataFrame(rows_true_base)\n",
    "\n",
    "    for df in (y_true_df, y_pred_df, x_like_df, y_true_with_base):\n",
    "        if 'window_id' in df: df['window_id'] = df['window_id'].astype('int32')\n",
    "        if 'time_step' in df: df['time_step'] = df['time_step'].astype('int8')\n",
    "        if 'close' in df: df['close'] = df['close'].astype('float32')\n",
    "        if 'pred_close' in df: df['pred_close'] = df['pred_close'].astype('float32')\n",
    "        if 'base_close' in df: df['base_close'] = df['base_close'].astype('float32')\n",
    "    return y_true_df, y_pred_df, x_like_df, y_true_with_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b01f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation hook: official metrics + trading (CSM, LOTQ)\n",
    "from metrics import evaluate_all_metrics   # expects y_true, y_pred, x_like (for base_close)\n",
    "import trading as tr                       # expects y_true with base_close inside\n",
    "\n",
    "def evaluate_on_val(model, X_val: np.ndarray, Y_val: np.ndarray, B_val: np.ndarray, device='cpu',\n",
    "                    max_batches: int = 4, batch_size: int = 256, horizon_step: int = 0):\n",
    "    \"\"\"\n",
    "    Run a few mini-batches of validation to keep cost small.\n",
    "    Returns a dict with official metrics and simple CSM/LOTQ trading snapshots.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N = X_val.shape[0]\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    preds_all, trues_all, bases_all = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for bi in range(min(max_batches, int(np.ceil(N / batch_size)))):\n",
    "            sel = idx[bi*batch_size : (bi+1)*batch_size]\n",
    "            x = torch.from_numpy(X_val[sel]).to(device)\n",
    "            y = torch.from_numpy(Y_val[sel]).to(device)\n",
    "            pred, _, _ = model(x)  # (B,10)\n",
    "            preds_all.append(pred.detach().cpu().numpy())\n",
    "            trues_all.append(y.detach().cpu().numpy())\n",
    "            bases_all.append(B_val[sel])\n",
    "\n",
    "    if not preds_all:\n",
    "        return {}\n",
    "\n",
    "    P = np.concatenate(preds_all, axis=0)   # (M,10)\n",
    "    T = np.concatenate(trues_all, axis=0)   # (M,10)\n",
    "    B = np.concatenate(bases_all, axis=0)   # (M,)\n",
    "\n",
    "    y_true_df, y_pred_df, x_like_df, y_true_with_base = batch_to_eval_frames(P, T, B, start_id=0)\n",
    "\n",
    "    off_stats = evaluate_all_metrics(y_true_df, y_pred_df, x_like_df)\n",
    "\n",
    "    # Trading snapshots at a chosen horizon (e.g., h=0)\n",
    "    ret_csm  = tr.CSM (y_true_with_base, y_pred_df, horizon_step=horizon_step)  # np.ndarray with one value\n",
    "    ret_lotq = tr.LOTQ(y_true_with_base, y_pred_df, horizon_step=horizon_step)\n",
    "\n",
    "    off_stats.update({\n",
    "        \"CSM_return\":  float(ret_csm.mean()),\n",
    "        \"LOTQ_return\": float(ret_lotq.mean()),\n",
    "    })\n",
    "    return off_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c1d0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1d1e32fdb44df6b20aeb6865c5fd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss=0.000856 recon=0.000773 kld=0.082517\n",
      "{'MSE': 0.000602, 'MAE': 0.01717, 'IC': 0.034383, 'IR': 4.450314, 'SharpeRatio': 1.667421, 'MDD': 0.0, 'VaR': -0.005678, 'ES': -0.008892, 'CSM_return': -7.8e-05, 'LOTQ_return': -0.000147}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8c336ab3754736bffd175c237c7d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] loss=0.000173 recon=0.000162 kld=0.011064\n",
      "{'MSE': 0.000587, 'MAE': 0.016784, 'IC': -0.00442, 'IR': -0.159909, 'SharpeRatio': 0.103426, 'MDD': 2.9e-05, 'VaR': -0.005792, 'ES': -0.008905, 'CSM_return': -0.000173, 'LOTQ_return': -5.8e-05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a478c081b8144e6f93684cf3bf469496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] loss=0.000154 recon=0.000151 kld=0.002188\n",
      "{'MSE': 0.000558, 'MAE': 0.016134, 'IC': 0.039804, 'IR': 1.376338, 'SharpeRatio': 1.728516, 'MDD': 0.000751, 'VaR': -0.005675, 'ES': -0.009007, 'CSM_return': -0.000309, 'LOTQ_return': -8e-06}\n",
      "Saved checkpoint to: c:\\Users\\xyy31\\Desktop\\ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit\\sample_submission\\tinytimevae_demo.pt\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 3           # increase for better quality\n",
    "LR = 1e-3\n",
    "BETA = 1e-3              # KL weight\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=0)\n",
    "\n",
    "# Model & optimizer\n",
    "model = TinyTimeVAE(input_dim=2, hidden=64, latent=16, input_len=60, horizon=10).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Train with periodic evaluation\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "    loss_avg, recon_avg, kld_avg, n_steps = 0.0, 0.0, 0.0, 0\n",
    "\n",
    "    for X, y in pbar:\n",
    "        X = X.to(torch.float32).to(DEVICE)     # (B,60,2)\n",
    "        y = y.to(torch.float32).to(DEVICE)     # (B,10)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        pred, mu, logvar = model(X)\n",
    "        loss, recon, kld = vae_loss(pred, y, mu, logvar, beta=BETA)\n",
    "        loss.backward()\n",
    "        if GRAD_CLIP is not None:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "        opt.step()\n",
    "\n",
    "        n_steps += 1\n",
    "        loss_avg  += (loss.item() - loss_avg) / n_steps\n",
    "        recon_avg += (recon - recon_avg) / n_steps\n",
    "        kld_avg   += (kld   - kld_avg)   / n_steps\n",
    "        pbar.set_postfix(loss=f\"{loss_avg:.5f}\", recon=f\"{recon_avg:.5f}\", kld=f\"{kld_avg:.5f}\")\n",
    "\n",
    "    print(f\"[Epoch {epoch}] loss={loss_avg:.6f} recon={recon_avg:.6f} kld={kld_avg:.6f}\")\n",
    "\n",
    "    # On-train evaluation (small batches for speed)\n",
    "    stats = evaluate_on_val(model, X_val, Y_val, B_val, device=DEVICE,\n",
    "                            max_batches=4, batch_size=256, horizon_step=0)\n",
    "    print({k: round(v, 6) for k, v in stats.items()})\n",
    "\n",
    "# Optionally save a checkpoint (not required for submission)\n",
    "CKPT = SUBM / \"tinytimevae_demo.pt\"\n",
    "torch.save(model.state_dict(), CKPT)\n",
    "print(\"Saved checkpoint to:\", CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infer on 500 / 50000 windows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580e8cc18bb64ead8be1842c15d4d130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Infer (subset):   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preview to c:\\Users\\xyy31\\Desktop\\ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit\\sample_submission\\submission_example.pkl  rows=5000  windows=500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>pred_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.112070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.112580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.113027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.113555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.113663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.113713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.119951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.116182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    window_id  time_step  pred_close\n",
       "0           1          0    0.092288\n",
       "1           1          1    0.108378\n",
       "2           1          2    0.111337\n",
       "3           1          3    0.112070\n",
       "4           1          4    0.112580\n",
       "5           1          5    0.113027\n",
       "6           1          6    0.113353\n",
       "7           1          7    0.113555\n",
       "8           1          8    0.113663\n",
       "9           1          9    0.113713\n",
       "10          6          0    0.119951\n",
       "11          6          1    0.116182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: This is a PREVIEW subset. For official submission, you must run full inference on ALL windows.\n"
     ]
    }
   ],
   "source": [
    "# Fast preview inference on a subset of x_test (NOT for official submission).\n",
    "# For official submission, run full inference over all windows.\n",
    "\n",
    "model.eval()\n",
    "FIRST_N_WINDOWS = 500       # set to an integer (e.g., 500). Set to None to disable.\n",
    "RANDOM_SEED     = 1337\n",
    "\n",
    "all_wids = x_test['window_id'].drop_duplicates().astype('int32').to_numpy()\n",
    "sel_wids = all_wids[:int(FIRST_N_WINDOWS)] if FIRST_N_WINDOWS is not None else all_wids # you need to run on all windows for official submission\n",
    "print(f\"Infer on {len(sel_wids)} / {len(all_wids)} windows\")\n",
    "\n",
    "out_rows = []\n",
    "it = x_test[x_test['window_id'].isin(sel_wids)].groupby('window_id', sort=False)\n",
    "for wid, g in tqdm(it, total=len(sel_wids), desc=\"Infer (subset)\"):\n",
    "    g = g.sort_values('time_step')  # expect 0..59\n",
    "    if g['time_step'].nunique() < 60:\n",
    "        # skip malformed windows in preview mode\n",
    "        continue\n",
    "\n",
    "    x_np = g[['close','volume']].to_numpy(np.float32)[None, ...]  # (1,60,2)\n",
    "    with torch.no_grad():\n",
    "        xt = torch.from_numpy(x_np).to(DEVICE)\n",
    "        pred, _, _ = model(xt)  # (1,10)\n",
    "        pred = pred.squeeze(0).detach().cpu().numpy()  # (10,)\n",
    "\n",
    "    for h in range(10):\n",
    "        out_rows.append({\n",
    "            'window_id': np.int32(wid),\n",
    "            'time_step': np.int8(h),\n",
    "            'pred_close': float(pred[h])\n",
    "        })\n",
    "\n",
    "submission_preview = pd.DataFrame(out_rows, columns=['window_id','time_step','pred_close'])\n",
    "submission_preview['window_id']  = submission_preview['window_id'].astype('int32')\n",
    "submission_preview['time_step']  = submission_preview['time_step'].astype('int8')\n",
    "submission_preview['pred_close'] = submission_preview['pred_close'].astype('float32')\n",
    "\n",
    "# Basic validation for the selected windows only\n",
    "counts = submission_preview.groupby('window_id')['time_step'].nunique()\n",
    "assert (counts == 10).all(), \"Each selected window_id must have exactly 10 rows (0..9).\"\n",
    "\n",
    "# Save preview (NOT for official submission)\n",
    "# For official submission, run inference on ALL windows and save to sample_submission/submission.pkl\n",
    "# out_path = SUBM / \"submission.pkl\"\n",
    "out_path = SUBM / \"submission_example.pkl\"\n",
    "submission_preview.to_pickle(out_path)\n",
    "print(f\"Saved preview to {out_path}  rows={len(submission_preview)}  \"\n",
    "      f\"windows={submission_preview['window_id'].nunique()}\")\n",
    "display(submission_preview.head(12))\n",
    "\n",
    "print(\"NOTE: This is a PREVIEW subset. For official submission, you must run full inference on ALL windows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
